from pathlib import Path
from warnings import filterwarnings

filterwarnings(action="ignore")

PROJECT_DIR = Path()
DATA_DIR = PROJECT_DIR / "dataset"


import matplotlib.pyplot as plt
import numpy as np
import pmdarima as pm
import statsmodels.api as sm
import statsmodels.tsa.api as tsa
import statsmodels.tsa.stattools as tst
from sklearn.metrics import (
    mean_absolute_error,
    mean_absolute_percentage_error,
    mean_squared_error,
)

INF_SUB = -1e-6

plt.style.use("seaborn-v0_8-whitegrid")
plt.rc("figure", autolayout=True, figsize=(12, 4))
plt.rc("axes", titleweight="bold")
plot_params = dict(
    color="0.75",
    style=".-",
    markeredgecolor="0.25",
    markerfacecolor="0.25",
    legend=False,
)

###################
# Model Selection #
###################


def store_level_auto_arima(
    store_df, families=None, horizon=30, trace=False, plot=False
):
    if not isinstance(families, list):
        families = store_df.columns

    results = pd.DataFrame(
        index=["model", "order", "seasonal_order", "aic", "mae", "mse", "mape"],
        columns=families,
    )

    for fam in families:
        print(f"\n{fam}\n")
        train = log_transform(store_df[fam].iloc[:-horizon])
        val = store_df[fam].iloc[-horizon:]
        model = pm.auto_arima(
            train,
            start_p=1,
            start_q=1,
            D=1,
            m=7,
            trend="ct",
            trace=trace,
        )
        print(f"AIC: {model.aic()}")
        fore = inverse_log_transform(model.predict(horizon))

        results.loc["model", fam] = model
        results.loc["order", fam] = model.order
        results.loc["seasonal_order", fam] = model.seasonal_order
        results.loc["aic", fam] = model.aic()
        results.loc["mae", fam] = mean_absolute_error(val, fore)
        results.loc["mse", fam] = mean_squared_error(val, fore)
        results.loc["mape", fam] = mean_absolute_percentage_error(val, fore)

        if plot:
            ax = (
                store_df[fam]
                .iloc[:-horizon]
                .rename("Train")
                .plot(**plot_params, figsize=(12, 5))
            )
            val.rename("Validation").plot(ax=ax, color="blue")
            fore.rename("Forecast").plot(ax=ax, color="red")
            ax.set_title(fam)
            ax.legend()

    return results


# def cross_validate(series, horizon=30, train_steps=183):
#   train_start = series.index[0]


#########
# Plots #
#########


def plot_weekly(series):
    weekly = pd.DataFrame(index=["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"])
    for time, grp in series.groupby(pd.Grouper(freq="W")):
        if len(grp.values) == 6:
            weekly[time.week] = np.insert(grp.values, 0, 0)
        elif len(grp.values) == 7:
            weekly[time.week] = grp.values

    weekly.plot(legend=False)


def store_plots(store_nbr, store_df, lags=20):
    nrows = store_df.shape[1]
    fig, axes = plt.subplots(nrows, 3, figsize=(25, 5 * nrows))
    fig.suptitle(f"Run Sequence, ACF and PACF Plots for Store No. {store_nbr}")

    for (fam, ser), ax in zip(store_df.items(), axes):
        ax[0].set_title(fam)
        ser.plot(ax=ax[0], **plot_params)

        ax[1].set_xlim(left=-1, right=lags + 2)
        ax[2].set_xlim(left=-1, right=lags + 2)
        sm.tsa.graphics.plot_acf(ser, ax=ax[1], lags=lags, zero=False)
        if not (ser.eq(0) | ser.eq(INF_SUB)).all():
            sm.tsa.graphics.plot_pacf(ser, ax=ax[2], lags=lags, zero=False)
        else:
            ax[2].set_ylim(bottom=-1, top=1)
            ax[2].set_title("Partial Autocorrelation")


#############
# Selection #
#############


def cross_validation_sarima(
    series,
    order,
    seasonal_order,
    trend,
    lookback=90,
    horizon=30,
    k=6,
    seed=42,
    plot=False,
):
    rng = np.random.default_rng(seed=seed)
    val_idx = rng.integers(low=lookback, high=len(series) - horizon, size=k)
    metrics = pd.DataFrame([], columns=["mae", "mse", "mape", "mrpd"])
    fig, axes = plt.subplots(k, figsize=(12, 4 * k))

    for i, ax in zip(val_idx, axes):
        train = series.iloc[0:i].rename("Train")
        val = series.iloc[i : i + horizon].rename("Validation")
        sar = tsa.statespace.SARIMAX(
            log_transform(train),
            order=order,
            seasonal_order=seasonal_order,
            trend=trend,
        ).fit(disp=0)
        y_pred = inverse_log_transform(sar.predict()).rename("Prediction")
        y_fore = inverse_log_transform(
            sar.predict(start=val.index[0], end=val.index[-1])
        ).rename("Forecast")
        metrics.loc[f"{val.index[0]}_{val.index[-1]}"] = pd.Series(
            {
                "mae": mean_absolute_error(val, y_fore),
                "mse": mean_squared_error(val, y_fore),
                "mape": mean_absolute_percentage_error(val, y_fore),
                "mrpd": mean_relative_percent_difference(val, y_fore),
            },
        )

        if plot:
            series.plot(ax=ax, **plot_params)
            y_pred.plot(ax=ax, color="cyan")
            y_fore.plot(ax=ax, color="magenta")
            ax.legend()

    return metrics


def grid_search_sarima(
    series, orders, seasonal_orders, trends, lookback=90, horizon=30, k=6, seed=42
):
    metrics = pd.DataFrame([], columns=["mae", "mse", "mape", "mrpd"])
    for trend in trends:
        for order in orders:
            for sorder in seasonal_orders:
                metrics.loc[f"{trend}_{order}_{sorder}"] = cross_validation_sarima(
                    series,
                    order,
                    sorder,
                    trend,
                    lookback=lookback,
                    horizon=horizon,
                    k=k,
                    seed=seed,
                ).mean()

    return metrics


def store_level_grid_search_sarima(
    store_df,
    orders,
    seasonal_orders,
    trends,
    lookback=90,
    horizon=30,
    k=6,
    seed=42,
    families=None,
):
    if not isinstance(families, list):
        families = store_df.columns

    store_metrics = {}

    for fam in families:
        store_metrics[fam] = grid_search_sarima(
            store_df[fam], orders, seasonal_orders, trends, lookback=90, horizon=30, k=6, seed=42
        )

    return store_metrics


def mean_relative_percent_difference(y_true, y_pred):
    return (2 * (y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))).mean()


#################
# Preprocessing #
#################


def store_level_preprocess(
    store_df,
    apply_log=False,
    d=None,
    D=None,
    m=None,
    use_adf=False,
):
    if use_adf:
        non_stat_cols = adf_non_stationary_families(store_level_adfs(store_df))
    else:
        non_stat_cols = list(store_df.columns)

    processed = store_df.copy()
    for fam, ser in processed.items():
        if apply_log:
            ser = log_transform(ser)

        if isinstance(d, int) and ser.name in non_stat_cols:
            for _ in range(d):
                ser = ser.diff()

        if isinstance(D, int) and isinstance(m, int):
            for _ in range(D):
                ser = ser.diff(m)

        processed[fam] = ser.fillna(0.0)

    return processed


def store_level_adfs(store_df):
    adfs = pd.DataFrame(
        index=[
            "Test Statistic",
            "p-value",
            "Lags Used",
            "Observations Used",
            "Critical Value (1%)",
            "Critical Value (5%)",
            "Critical Value (10%)",
        ],
        columns=store_df.columns,
    )

    for i, fam in enumerate(store_df):
        adf = tst.adfuller(store_df[fam])
        adfs.iloc[0:4, i] = adf[0:4]
        for thresh, crit in adf[4].items():
            adfs.loc[f"Critical Value ({thresh})", fam] = crit

    return adfs


def adf_non_stationary_families(adfs):
    truths = adfs.loc["Test Statistic"].ge(adfs.loc["Critical Value (1%)"])

    return list(truths[truths].index)


def log_transform(ser):
    ser = np.log(ser)
    # Replace `-inf` values with INF_SUB.
    ser[ser == -np.inf] = INF_SUB

    return ser


def inverse_log_transform(ser):
    # Restore the `-inf` values for exponentiation.
    ser[ser == INF_SUB] = -np.inf

    return np.exp(ser)


import pandas as pd

store_sales = (
    pd.read_csv(
        DATA_DIR / "train.csv", parse_dates=["date"], dtype={"sales": "float32"}
    )
    .set_index(["date"])
    .to_period(freq="D")
    .set_index(["store_nbr", "family"], append=True)["sales"]
    .unstack()
    .unstack()
)

# Fill in values for missing dates.
missing_idx = set(
    pd.date_range(
        store_sales.index[0].to_timestamp(), store_sales.index[-1].to_timestamp()
    ).to_period()
) - set(store_sales.index.get_level_values(level=0).unique())
for idx in missing_idx:
    store_sales.loc[idx] = 0.0

store_sales = store_sales.stack().sort_index(level=0)
store_sales


store_level_sales = []
for group, frame in store_sales.groupby(level=1):
    store_level_sales.append((group, frame.reset_index(level=1, drop=True)))

store_level_sales = dict(store_level_sales)


STORE_NO = 2
FAMILY = "GROCERY II"
y = store_level_sales[STORE_NO][FAMILY]


df = store_level_preprocess(
    store_level_sales[STORE_NO],
    apply_log=True,
    d=0,
    D=1,
    m=7,
    use_adf=True,
)
store_plots(STORE_NO, df, lags=60)


# results_s1 = store_level_auto_arima(
#     store_level_sales[2], families=["AUTOMOTIVE"], horizon=30, plot=True
# )
# results_s1


cvm = cross_validation_sarima(
    y, order=(1, 0, 0), seasonal_order=(2, 1, 0, 7), trend=None, plot=True
)


cvm.mean()


metrics = store_level_grid_search_sarima(
    store_level_sales[2],
    orders=[(1, 0, 0), (2, 0, 0)],
    seasonal_orders=[(1, 1, 0, 7), (2, 1, 0, 7)],
    trends=[None],
);


from ast import literal_eval

for f, frame in metrics.items():
    idx = frame["mae"].sort_values().index[-1]
    print(f"{f}\n{frame.loc[idx]}")


import statsmodels.tsa.api as tsa

y = store_level_sales[2]["GROCERY II"]
y_train = y.iloc[:-30]
y_test = y.iloc[-30:]
sarima = tsa.statespace.SARIMAX(
    log_transform(y_train),
    order=(1, 0, 0),
    seasonal_order=(2, 1, 0, 7),
    trend=None,
).fit(full_output=0)
y_pred = inverse_log_transform(sarima.predict())
y_fore = inverse_log_transform(
    sarima.predict(start=y_test.index[0], end=y_test.index[-1])
)

ax = y.plot(**plot_params)
y_pred.plot(ax=ax, color="cyan")
y_fore.plot(ax=ax, color="red")
ax.set_title("GROCERY II")


mean_absolute_error(y_train, y_pred), mean_squared_error(
    y_train, y_pred
), mean_absolute_percentage_error(y_train, y_pred)


mean_absolute_error(y_test, y_fore), mean_squared_error(
    y_test, y_fore
), mean_absolute_percentage_error(y_test, y_fore)


y_train[y_train == 0] = 0.5
np.abs((y_train - y_pred.shift(-7)) / y_train).mean(), y_train, y_pred


import statsmodels.tsa.api as tsa

get_ipython().run_line_magic('pinfo',  'tsa.statespace.SARIMAX.fit')



